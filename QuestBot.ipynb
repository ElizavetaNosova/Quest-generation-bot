{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "QuestBot.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXvJvpaAtvG2"
      },
      "source": [
        "!pip install cpufeature\n",
        "!pip install triton==0.2.3\n",
        "!DS_BUILD_CPU_ADAM=1 DS_BUILD_SPARSE_ATTN=1 pip install deepspeed==0.3.7\n",
        "!pip install transformers==3.5.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZpoJ6PCuwBI"
      },
      "source": [
        "!pip install --no-cache-dir pytelegrambotapi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPiXw9ebubfX",
        "outputId": "f933035d-4871-4326-d193-78df961857f2"
      },
      "source": [
        "import telebot\n",
        "import uuid\n",
        "import os\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import sent_tokenize, wordpunct_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "import string\n",
        "from copy import copy\n",
        "import random\n",
        "import re\n",
        "\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaK00hW2j6K6"
      },
      "source": [
        "#!mkdir /home/jovyan/devices/quests/generated_quests"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4L5O82jDAdWT",
        "outputId": "3bab7841-feac-4d2d-b88d-ea06da93ecd3"
      },
      "source": [
        "token = '' #here should be token\n",
        "bot = telebot.TeleBot(token)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/home/user/conda/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDrdYgEMvTXI"
      },
      "source": [
        "MODEL_PATH = \"/home/jovyan/devices/quests/hf\"\n",
        "TOKENIZER_PATH = \"/home/jovyan/devices/quests/hf\"\n",
        "QUEST_DIRECTORY = '/home/jovyan/devices/quests/generated_quests'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFDt24GB0YkF"
      },
      "source": [
        "gpt_model = GPT2LMHeadModel.from_pretrained(MODEL_PATH)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(TOKENIZER_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEhjtPBk4TWo",
        "outputId": "e196adc3-7529-43ee-e7b1-da1819364b3d"
      },
      "source": [
        "gpt_model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50257, 1536)\n",
              "    (wpe): Embedding(2048, 1536)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0): Block(\n",
              "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): Block(\n",
              "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): Block(\n",
              "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): Block(\n",
              "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): Block(\n",
              "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): Block(\n",
              "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): Block(\n",
              "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): Block(\n",
              "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): Block(\n",
              "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): Block(\n",
              "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): Block(\n",
              "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): Block(\n",
              "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (12): Block(\n",
              "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (13): Block(\n",
              "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (14): Block(\n",
              "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (15): Block(\n",
              "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (16): Block(\n",
              "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (17): Block(\n",
              "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (18): Block(\n",
              "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (19): Block(\n",
              "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (20): Block(\n",
              "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (21): Block(\n",
              "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (22): Block(\n",
              "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (23): Block(\n",
              "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=1536, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itEFdOAZvjhI"
      },
      "source": [
        "#os.mkdir(QUEST_DIRECTORY)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9nRb82JAdWV"
      },
      "source": [
        "def calc_perplexity(input_idx, gpt2model):\n",
        "    loss = gpt_model(input_idx, labels=input_idx)[0]\n",
        "    return loss.exp()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtqSMD59AdWV"
      },
      "source": [
        "ru_stopwords = stopwords.words('russian')\n",
        "stemmer = SnowballStemmer('russian')\n",
        "punctuation = string.punctuation + '«»'\n",
        "\n",
        "def get_stem_set(text):\n",
        "    tokens = [token for token in wordpunct_tokenize(text) if token not in ru_stopwords and token not in punctuation]\n",
        "    return set([stemmer.stem(token) for token in tokens])\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rRkokHeAdWW"
      },
      "source": [
        "class NextFragmentCandidate:\n",
        "    def __init__(self, text:str, gpt2model, tokenizer, pretext='', posttext=''):\n",
        "        self.text = text\n",
        "        joined_text = pretext+text+posttext\n",
        "        self.input_idx = tokenizer.encode(joined_text, return_tensors='pt').cuda()\n",
        "        self.perplexity = calc_perplexity(self.input_idx, gpt2model)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.input_idx.shape[-1]    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaANaoiDAdWX"
      },
      "source": [
        "class Story: \n",
        "    def __init__(self, beginning:str, middle_fragments:list, endings:list, gpt2model, tokenizer, beginning_stem_set=None, max_score2suggest=5000):\n",
        "        self.beginning = beginning\n",
        "        self.beginning_stem_set = beginning_stem_set if beginning_stem_set else get_stem_set(beginning)\n",
        "        \n",
        "        self.pretext = 'BOF'\n",
        "        self.gpt2model = gpt2model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.threshold = max_score2suggest\n",
        "        \n",
        "        self.middle_part_fragments = self.__get_fragments_field(middle_fragments)\n",
        "        self.endings = self.__get_fragments_field(endings)\n",
        "        \n",
        "    def score_beginning_suitability(self, text, text_stem_set):\n",
        "        if text.lower().strip() == self.beginning.lower().strip():\n",
        "            return 1.1\n",
        "        elif not text_stem_set or not self.beginning_stem_set:\n",
        "            return 0\n",
        "        else: \n",
        "            return len(self.beginning_stem_set.intersection(text_stem_set))/min(len(self.beginning_stem_set), len(text_stem_set))\n",
        "      \n",
        "    def __get_fragments_field(self, fragments:list):\n",
        "        if all([isinstance(fragment, NextFragmentCandidate) for fragment in fragments]):\n",
        "            return copy(fragments)\n",
        "        elif all([isinstance(fragment, str) for fragment in fragments]):\n",
        "            return [NextFragmentCandidate(fragment, self.gpt2model, self.tokenizer, pretext=self.pretext) for fragment in fragments]\n",
        "        else:\n",
        "            raise ValueError('fragments should be str or NextFragmentCandidate objects')\n",
        "    \n",
        "    def __score_next_fragment_candidate(self, text, next_fragment_candidate:NextFragmentCandidate, pretext='BOF', intertext='BOF', posttext=''):\n",
        "        joined_text = pretext + text + intertext + next_fragment_candidate.text + posttext\n",
        "        input_idx = self.tokenizer.encode(joined_text, return_tensors='pt').cuda()\n",
        "        joined_text_len = input_idx.shape[-1]\n",
        "        joined_text_perplexity = calc_perplexity(input_idx, self.gpt2model)\n",
        "        score = (joined_text_perplexity-next_fragment_candidate.perplexity)/(joined_text_len-len(next_fragment_candidate))\n",
        "        return float(score)\n",
        "    \n",
        "    def remove_candidate(self, text, next_fragment_type):\n",
        "        if next_fragment_type == 'standart':\n",
        "            self.middle_part_fragments = [candidate for candidate in self.middle_part_fragments if candidate.text != text]\n",
        "        elif next_fragment_type == 'ending':\n",
        "            self.endings = [candidate for candidate in self.endings if candidate.text != text]\n",
        "        else:\n",
        "            raise ValueError('next candidate type should be \"standart\" or \"ending\"')\n",
        "        \n",
        "    \n",
        "    def suggest_best_next(self, previous_fragment, next_fragment_type, remove_candidate=True):\n",
        "        if next_fragment_type == 'standart':\n",
        "            next_fragment_candidates = self.middle_part_fragments\n",
        "            is_ending = False\n",
        "        elif next_fragment_type == 'ending':\n",
        "            next_fragment_candidates = self.endings\n",
        "            is_ending = True\n",
        "        else:\n",
        "            next_fragment_candidates = None\n",
        "        if next_fragment_candidates:\n",
        "            scored_fragments = [(next_fragment_candidate.text, self.__score_next_fragment_candidate(previous_fragment, next_fragment_candidate)) for next_fragment_candidate in next_fragment_candidates]\n",
        "            sorted_scored_fragments = sorted(scored_fragments, key = lambda x: x[1])\n",
        "            best_candidate_data = sorted_scored_fragments[0]\n",
        "            if best_candidate_data[1] <= self.threshold:\n",
        "                best_next_text = best_candidate_data[0]\n",
        "                if remove_candidate:\n",
        "                    self.remove_candidate(best_next_text, next_fragment_type)\n",
        "                return best_next_text, is_ending\n",
        "            else:\n",
        "                return None, False\n",
        "        else:\n",
        "            return None, False\n",
        "    \n",
        "    def copy(self):\n",
        "        return Story(copy(self.beginning), copy(self.middle_part_fragments), copy(self.endings), self.gpt2model, self.tokenizer, copy(self.beginning_stem_set), copy(self.threshold))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1kdWsGYAdWa"
      },
      "source": [
        "stories_data = [\n",
        "    [\n",
        "        'Вы идете по зимнему лесу и слышите детский крик.',\n",
        "        [\n",
        "             'Вы выходите на поляну и видите недостроенный стул из снега, возле которого лежит грустный плюшевый мишка. Хотите достроить?',\n",
        "             'Вы подошли к выходу из леса и еще можете успеть на последний автобус в город. Но вы так и не выяснили, что произошло с ребенком. Что будете делать?',\n",
        "             'Вы выходите к поляне, надеетесь, что идти по ней будет легче. Делаете шаг вперед и проваливаетесь по пояс. Развернетесь?',\n",
        "             'Вы слышите тот же детский голос снова. Но теперь ребенок не кричит, а репетирует «Я помню чудное мгновенье». Но почему он делает это в лесу?',\n",
        "             'Вы обнаруживаете следы на снегу, размер ноги определенно не как у ребенка. Посмотрите, куда они ведут.',\n",
        "             'Вы совсем забыли, откуда пришли. Может, найти дорогу назад важнее, чем понять, откуда доносились звуки?'\n",
        "        ],\n",
        "        [\n",
        "            'Между деревьев вы обнаруживаете колонку, из которой доносится тот же детский крик. Вы выключаете ее, чтобы звуки больше никого не сбили с толку.',\n",
        "            'Теперь голос доносится сверху, причем очень близко. Под вашими ногами валяется ботинок, ребенок сидит наверху и не хочет слезать в сугроб. Вы подаете ему обувь, он благодарит вас и говорит, что слезет, когда захочет.'\n",
        "        ]\n",
        "    ]\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4bXWoRWAdWc"
      },
      "source": [
        "stories = [Story(*story_data, gpt_model, tokenizer) for story_data in stories_data]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lcvG5sSAdWd"
      },
      "source": [
        "class UserStoryOrganizer:\n",
        "    def __init__(self, story, min_steps_from_previous=3, min_story_len=8):\n",
        "        self.story = story.copy()\n",
        "        self.steps_from_beginning = 0\n",
        "        self.steps_from_previous = 0\n",
        "        \n",
        "        self.min_steps_from_previous = min_steps_from_previous\n",
        "        self.min_story_len = min_story_len\n",
        "        \n",
        "    def __get_best_next_human_written_types(self, ignore_num_steps_from_previous=False):\n",
        "        if self.steps_from_previous <= self.min_steps_from_previous or ignore_num_steps_from_previous:\n",
        "            if self.steps_from_beginning <= self.min_story_len:\n",
        "                return ['standart']\n",
        "            else:\n",
        "                return ['ending', 'standart']\n",
        "        else:\n",
        "            return []\n",
        "        \n",
        "    def increase_steps_counters(self):\n",
        "        self.steps_from_beginning += 1\n",
        "        self.steps_from_previous += 1\n",
        "        \n",
        "    def suggest_next_fragment(self, previous_text, increase_counters=False, ignore_num_steps_from_previous=False):\n",
        "        next_fragment = None\n",
        "        is_ending = False\n",
        "        suitable_next_types = self.__get_best_next_human_written_types(ignore_num_steps_from_previous)\n",
        "        if suitable_next_types:\n",
        "            for next_fragment_type in suitable_next_types:\n",
        "                next_fragment, is_ending = self.story.suggest_best_next(previous_text, next_fragment_type)\n",
        "                if next_fragment:\n",
        "                    break\n",
        "        if increase_counters:\n",
        "            self.increase_steps_counters()\n",
        "        if next_fragment:\n",
        "            self.steps_from_previous = 0\n",
        "        return next_fragment, is_ending\n",
        "    \n",
        "    def time_for_human_written(self, increase_counter=True):\n",
        "        if increase_counter:\n",
        "            self.increase_steps_counters()\n",
        "        return self.steps_from_previous >= self.min_steps_from_previous"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVJMfgD3AdWd"
      },
      "source": [
        "class StoryFragmentsManager:\n",
        "    def __init__(self, stories:list, starting_story_treshold=0.7):\n",
        "        self.stories = stories\n",
        "        self.__user_story_organizers = {}\n",
        "        self.starting_story_treshold = starting_story_treshold\n",
        "        \n",
        "    def get_random_story_beginning(self):\n",
        "        story = random.choice(self.stories)\n",
        "        return story.beginning\n",
        "    \n",
        "    def set_story(self, session_id, story):\n",
        "        self.__user_story_organizers[session_id] = UserStoryOrganizer(story)\n",
        "        \n",
        "    def forget_story(self, session_id):\n",
        "        if session_id in self.__user_story_organizers:\n",
        "            del self.__user_story_organizers[session_id]\n",
        "    \n",
        "    def analyze_user_input_first_fragment(self, session_id, user_input):\n",
        "        suitable_story = None\n",
        "        suitable_story_score = 0\n",
        "        input_stem_set = get_stem_set(user_input)\n",
        "        for story in self.stories:\n",
        "            story_score = story.score_beginning_suitability(user_input, input_stem_set)\n",
        "            if story_score > suitable_story_score and story_score > self.starting_story_treshold:\n",
        "                suitable_story = story\n",
        "                suitable_story_score = story_score\n",
        "                if story_score > 1:\n",
        "                    break\n",
        "        if suitable_story:\n",
        "            self.set_story(session_id, suitable_story)\n",
        "            \n",
        "    def suggest_next_fragment(self, session_id, previous_fragment):\n",
        "        if session_id not in self.__user_story_organizers:\n",
        "            return None, False\n",
        "        else:\n",
        "            text, is_ending = self.__user_story_organizers[session_id].suggest_next_fragment(previous_fragment)\n",
        "            return text, is_ending\n",
        "        \n",
        "    def time_for_human_written(self, session_id, increase_counters=True):\n",
        "        return session_id in self.__user_story_organizers and self.__user_story_organizers[session_id].time_for_human_written(increase_counters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYLj6sivtwEd",
        "outputId": "30ee6185-9674-411e-d72d-724f2ad1ac13"
      },
      "source": [
        "class ChatSessionsFilesOrganizer:\n",
        "    \n",
        "    def __init__(self, directory, extension='.txt', encoding='utf-8'):\n",
        "        self.__chat_id2current_quest_file = {}\n",
        "        self._directory = directory\n",
        "        self._extension = extension\n",
        "        self._encoding = encoding\n",
        "    \n",
        "    def create_new_quest_file(self, session_id, start_text=''):\n",
        "        quest_id = uuid.uuid1().hex\n",
        "        file_name = quest_id + self._extension\n",
        "        self.__chat_id2current_quest_file[session_id] = file_name\n",
        "        file_path = os.path.join(self._directory, file_name)\n",
        "        with open(file_path, 'w', encoding=self._encoding) as f:\n",
        "            if start_text:\n",
        "                f.write(start_text)\n",
        "        \n",
        "    def get_current_quest_file_path(self, session_id):\n",
        "        if session_id not in self.__chat_id2current_quest_file:\n",
        "            self.create_new_quest_file(session_id)\n",
        "        current_quest_file = self.__chat_id2current_quest_file[session_id]\n",
        "        current_quest_path = os.path.join(self._directory, current_quest_file)\n",
        "        return current_quest_path\n",
        "    \n",
        "    def get_current_quest_text(self, session_id):\n",
        "        quest_file_path = self.get_current_quest_file_path(session_id)\n",
        "        with open(quest_file_path, encoding=self._encoding) as f:\n",
        "            text = f.read()\n",
        "        return text\n",
        "    \n",
        "    def add_next_part(self, session_id, new_fragment, separator='\\n'):\n",
        "        file_path = self.get_current_quest_file_path(session_id)\n",
        "        with open(file_path, 'a', encoding=self._encoding) as f:\n",
        "            f.write(separator + new_fragment)\n",
        "            \n",
        "    def get_last_fragment(self, session_id, fragments_separator):\n",
        "        text = self.get_current_quest_text(session_id)\n",
        "        last_fragment = text.split(fragments_separator)[-1]\n",
        "        return last_fragment\n",
        "    \n",
        "    def unlink_file(self, session_id):\n",
        "        if session_id in self.__chat_id2current_quest_file:\n",
        "            del self.__chat_id2current_quest_file[session_id]\n",
        " \n",
        " \n",
        "class GptGenerator:\n",
        "    def __init__(self, gpt_model, tokenizer, max_pretext_length = 2048, default_not_greedy_temperature=1.5, default_greedy_temperature=1):\n",
        "        self.gpt_model = gpt_model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.__max_pretext_length = max_pretext_length\n",
        "        self.tokenizer.add_special_tokens({\"bos_token\": \"<s>\"})\n",
        "        self.tokenizer.add_special_tokens({\"eos_token\": \"</s>\"})      \n",
        "        \n",
        "        self.default_greedy_temperature = default_greedy_temperature\n",
        "        self.default_not_greedy_temperature = default_not_greedy_temperature\n",
        "    \n",
        "     \n",
        "    def get_next_steps(self, text, max_length=200, greedy=False, temperature=None, num_beams=None):\n",
        "        pretext_length = len(text)\n",
        "        input_idx = self.tokenizer.encode(text, return_tensors='pt').cuda()\n",
        "        if input_idx.shape[1] > self.__max_pretext_length:\n",
        "            print('Обрезаем претекст')\n",
        "            input_idx = input_idx[:, -self.__max_pretext_length:]\n",
        "            used_pretext = tokenizer.decode(input_idx[0])\n",
        "            pretext_length = len(used_pretext)\n",
        "        if temperature == None:\n",
        "            if greedy:\n",
        "                temperature = self.default_greedy_temperature\n",
        "            else:\n",
        "                temperature = self.default_not_greedy_temperature\n",
        "        if greedy:\n",
        "             encoded_new_text = self.gpt_model.generate(input_idx, max_length=pretext_length+max_length, temperature=temperature, repetition_penalty=5.0, top_k=5, top_p=0.95, do_sample=True)[0]\n",
        "        else:\n",
        "            encoded_new_text = self.gpt_model.generate(input_idx, do_sample=True, max_length=pretext_length+max_length, num_beams=num_beams, temperature=temperature)[0]\n",
        "        new_text = self.tokenizer.decode(encoded_new_text)\n",
        "        return new_text[pretext_length:]\n",
        "\n",
        "\n",
        "help_message_text =  'Я бот, я могу сгенерировать квест! Введите команду /start, чтобы начать новый квест.'\n",
        "start_message_text = 'Нажмите на кнопку с началом квеста или придумайте свое'\n",
        "suggest_new_quest_button_text = 'Начать новый квест'\n",
        "    \n",
        "class QuestGenerator:\n",
        "    def __init__(self, model, tokenizer, quests_directory, stories, starting_story_treshold=0.7, end_button_text=suggest_new_quest_button_text, ending_text='Квест завершен!'):\n",
        "        self.__gpt2generator = GptGenerator(model, tokenizer)\n",
        "        self.__human_written_stories_manager = StoryFragmentsManager(stories, starting_story_treshold)\n",
        "        self.__files_organizer = ChatSessionsFilesOrganizer(quests_directory)\n",
        "        self.__start_quest_tag = 'BOQ'\n",
        "        self.__end_quest_tag = 'EOQ'\n",
        "        self.__start_fragment_tag = 'BOF'\n",
        "        self.__button_tag = 'BUTTON'\n",
        "        self.__input_tag = 'INPUT'\n",
        "        self.separator = '\\n'\n",
        "        self.end_button_text = end_button_text\n",
        "        self.ending_text = ending_text\n",
        "        \n",
        "        self.max_button_len = 30\n",
        "        self.max_fragment_len = 100\n",
        "    \n",
        "    def new_quest(self, session_id):\n",
        "        self.__files_organizer.create_new_quest_file(session_id)\n",
        "        \n",
        "    def suggest_beginning(self):\n",
        "        return self.__human_written_stories_manager.get_random_story_beginning()\n",
        "        \n",
        "    def save_first_fragment(self, session_id, text):\n",
        "        self.__human_written_stories_manager.analyze_user_input_first_fragment(session_id, text)\n",
        "        self.save_fragment(session_id, text)\n",
        "    \n",
        "    def save_fragment(self, session_id, text):\n",
        "        new_fragment = self.separator.join([self.__start_fragment_tag, text])\n",
        "        self.__files_organizer.add_next_part(session_id, new_fragment)\n",
        "        \n",
        "    def generate_buttons(self, session_id):\n",
        "        text = self.__files_organizer.get_current_quest_text(session_id)\n",
        "        text  = self.__make_text_end_with(text, self.__button_tag)\n",
        "        generated_next_steps = self.__gpt2generator.get_next_steps(text)\n",
        "        button_texts = self.__clean_and_save_button_texts(session_id, generated_next_steps) \n",
        "        return button_texts\n",
        "       \n",
        "    def save_input(self, session_id, user_input):\n",
        "        new_fragment = self.separator.join([self.__input_tag, user_input])\n",
        "        self.__files_organizer.add_next_part(session_id, new_fragment)\n",
        "        \n",
        "    def generate_fragment(self, session_id):\n",
        "        is_ending = False\n",
        "        fragment_text = None\n",
        "        buttons_plain_text = ''\n",
        "        if self.__human_written_stories_manager.time_for_human_written(session_id):\n",
        "            full_previous_fragment = self.__files_organizer.get_last_fragment(session_id, fragments_separator=self.__start_fragment_tag)\n",
        "            previous_fragment = full_previous_fragment.split(self.__button_tag)[0] + full_previous_fragment.split(self.__input_tag)[-1]\n",
        "            fragment_text, is_ending = self.__human_written_stories_manager.suggest_next_fragment(session_id, previous_fragment)\n",
        "        if not fragment_text:\n",
        "            text = self.__files_organizer.get_current_quest_text(session_id)\n",
        "            text = self.__make_text_end_with(text, self.__start_fragment_tag)\n",
        "            generated_next_steps = self.__gpt2generator.get_next_steps(text)  \n",
        "            generated_next_steps = generated_next_steps.split(self.__start_fragment_tag)[0]\n",
        "            generated_next_steps = generated_next_steps.split(self.__input_tag)[0]\n",
        "            \n",
        "            if self.__end_quest_tag in generated_next_steps:\n",
        "                fragment_text = generated_next_steps.split(self.__end_quest_tag)[0] \n",
        "                fragment_text = generated_next_steps.split(self.__button_tag)[0] \n",
        "                is_ending = True\n",
        "            elif self.__button_tag not in generated_next_steps:\n",
        "                fragment_text = self.__strip_text(generated_next_steps, self.max_fragment_len)\n",
        "            else:\n",
        "                parts = generated_next_steps.split(self.__button_tag)\n",
        "                fragment_text = parts[0]\n",
        "                buttons_plain_text = self.__button_tag.join(parts[1:])\n",
        "                fragment_text = self.__strip_text(fragment_text, self.max_fragment_len)\n",
        "                self.save_fragment(session_id, fragment_text)\n",
        "                #if buttons are generated and we can be sure that at least one button text is finished\n",
        "        if is_ending:\n",
        "            self.__human_written_stories_manager.forget_story(session_id)\n",
        "            self.__files_organizer.unlink_file(session_id)\n",
        "            button_texts = [self.end_button_text]\n",
        "            fragment_text = fragment_text.split(self.__end_quest_tag)[0]\n",
        "            fragment_text = ' '.join([fragment_text, self.ending_text])\n",
        "        elif buttons_plain_text:\n",
        "            button_texts = self.__clean_and_save_button_texts(session_id, buttons_plain_text)\n",
        "        else:\n",
        "            button_texts = []\n",
        "        return fragment_text, button_texts, is_ending\n",
        "            \n",
        "    def __strip_text(self, text, max_len):\n",
        "        stripped_text = text\n",
        "        if len(text) > max_len:\n",
        "            #ToDo: может генериться текст без точек,\n",
        "            #надо будет сюда добавить дробление подозрительно больших предложений другим способом\n",
        "            sents = [sent for sent in sent_tokenize(text) if sent.strip()]\n",
        "            if len(sents[0]) > max_len:\n",
        "                stripped_text = sents[0]\n",
        "            else:\n",
        "                chosen_sents = []\n",
        "                separator = ' '\n",
        "                current_len = 0\n",
        "                for sent in sents:\n",
        "                    current_len += len(sent)\n",
        "                    if current_len < max_len:\n",
        "                        chosen_sents.append(sent)\n",
        "                        current_len += len(separator)\n",
        "                    else:\n",
        "                        break\n",
        "                stripped_text = separator.join(chosen_sents)\n",
        "        return stripped_text\n",
        "    \n",
        "    def __make_text_end_with(self, text, tag):\n",
        "        if not text.strip().endswith(tag):\n",
        "            text = self.separator.join([text, tag])\n",
        "        return text\n",
        "    \n",
        "    def __clean_and_save_button_texts(self, session_id, generated_buttons_steps):\n",
        "        buttons_plain_text = generated_buttons_steps.split(self.__end_quest_tag)[0]\n",
        "        buttons_plain_text = generated_buttons_steps.split(self.__start_fragment_tag)[0]\n",
        "        buttons_plain_text = generated_buttons_steps.split(self.__input_tag)[0]\n",
        "       \n",
        "         \n",
        "        button_texts = []\n",
        "        if self.__button_tag in buttons_plain_text:\n",
        "            button_texts = [self.__strip_text(button_text, self.max_button_len) for button_text in buttons_plain_text.split(self.__button_tag) if button_text.strip()]\n",
        "        #Если только одна кнопка без тэга окончания\n",
        "        if not button_texts:\n",
        "            button_texts = [self.__strip_text(buttons_plain_text, self.max_button_len)]\n",
        "        #ToDo Если не было тэга инпута, проверять, что последняя кнопка является полноценным текстом\n",
        "        self.__save_button_texts(session_id, button_texts)\n",
        "        return button_texts\n",
        "    \n",
        "    def __save_button_texts(self, session_id, button_texts):\n",
        "        button_fragments = [self.separator.join([self.__button_tag, button_text]) for button_text in button_texts]\n",
        "        new_fragment = self.separator.join(button_fragments)\n",
        "        self.__files_organizer.add_next_part(session_id, new_fragment)\n",
        "        "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxA91BnhhWwr"
      },
      "source": [
        "quest_generator = QuestGenerator(gpt_model, tokenizer, QUEST_DIRECTORY, stories) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ned30q6-hRDd",
        "outputId": "bb7ba5cc-a197-42be-ca93-fe1404020a81"
      },
      "source": [
        "def inform_about_long_operation(chat_id):\n",
        "    try:\n",
        "        bot.send_message(chat_id, 'Пожалуйста, подождите', reply_markup=telebot.types.ReplyKeyboardRemove())\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "def report_about_error(chat_id):\n",
        "    try:\n",
        "        bot.send_message(chat_id, 'Произошла непредвиденная ошибка')\n",
        "    except Exception as e:\n",
        "        print(е)\n",
        "        print('Сообщение об ошибке не отправлено')\n",
        "\n",
        "@bot.message_handler(commands=['help'])\n",
        "def help_message(message):\n",
        "    try:\n",
        "        bot.send_message(message.chat.id, help_message_text, reply_markup=telebot.types.ReplyKeyboardRemove())\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        report_about_error(message.chat.id)\n",
        "    \n",
        "@bot.message_handler(commands=['start'])\n",
        "def start_message(message):\n",
        "    try:\n",
        "        quest_generator.new_quest(message.chat.id)\n",
        "        suggested_beginning = quest_generator.suggest_beginning()\n",
        "        keyboard = telebot.types.ReplyKeyboardMarkup(True, one_time_keyboard=True)\n",
        "        keyboard.row(suggested_beginning)\n",
        "        bot.send_message(message.chat.id, start_message_text, reply_markup=keyboard)\n",
        "        bot.register_next_step_handler(message, process_first_fragment)\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        report_about_error(message.chat.id)\n",
        "\n",
        "def check_buttons(buttons):\n",
        "    buttons = [button for button in buttons if re.search('[А-ЯЁа-яёA-Za-z]', button)]\n",
        "    if not buttons:\n",
        "        buttons = ['Далее']\n",
        "    return buttons\n",
        "        \n",
        "def process_first_fragment(message):\n",
        "    try:\n",
        "        inform_about_long_operation(message.chat.id)\n",
        "        text = message.text\n",
        "        quest_generator.save_first_fragment(message.chat.id, text)\n",
        "        buttons = check_buttons(quest_generator.generate_buttons(message.chat.id))\n",
        "        keyboard = telebot.types.ReplyKeyboardMarkup(True, one_time_keyboard=True)\n",
        "        keyboard.row(*buttons)\n",
        "        #keyboard = telebot.types.InlineKeyboardMarkup()\n",
        "        #for b in buttons:\n",
        "        #   print(b)\n",
        "        #   keyboard.add(telebot.types.InlineKeyboardButton(b,callback_data=b[:30]))\n",
        "        bot.send_message(message.chat.id, 'Выберите одну из кнопок или введите свой вариант', reply_markup=keyboard)\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        report_about_error(message.chat.id)\n",
        "\n",
        "@bot.message_handler(content_types=['text'])\n",
        "def user_input(message):\n",
        "    try:\n",
        "    ##ToDo обрабатывать случаи, когда пользователь отправляет сообщение раньше, чем получил ответ на предыдущее\n",
        "        if message.text == suggest_new_quest_button_text:\n",
        "            start_message(message)\n",
        "        else:\n",
        "            inform_about_long_operation(message.chat.id)\n",
        "            quest_generator.save_input(message.chat.id, message.text)\n",
        "            fragment_text, buttons, is_ending = quest_generator.generate_fragment(message.chat.id)\n",
        "            if not fragment_text.strip():\n",
        "                fragment_text = 'Простите, бот не смог сгенерировать текст'\n",
        "            if not buttons and not is_ending:\n",
        "                buttons = quest_generator.generate_buttons(message.chat.id)  \n",
        "            buttons = check_buttons(buttons)\n",
        "            keyboard = telebot.types.ReplyKeyboardMarkup(True, one_time_keyboard=True)\n",
        "            keyboard.row(*buttons)\n",
        "            #keyboard = telebot.types.InlineKeyboardMarkup()\n",
        "            #for b in buttons:\n",
        "            #    print(b)\n",
        "            #    keyboard.add(telebot.types.InlineKeyboardButton(b,callback_data=b[:30]))\n",
        "            bot.send_message(message.chat.id, fragment_text, reply_markup=keyboard)\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        report_about_error(message.chat.id)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    bot.polling()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8xFekI_AdWh"
      },
      "source": [
        "## Примеры работы выбранной формулы ранжирования"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVzXsyDwAdWi"
      },
      "source": [
        "def get_fixed_part_coefs(fixed_part):\n",
        "    input_idx = tokenizer.encode(fixed_part, return_tensors='pt').cuda()\n",
        "    loss = gpt_model(input_idx, labels=input_idx)[0]\n",
        "    return loss.exp(), input_idx.shape[-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vK2bvGM5AdWi"
      },
      "source": [
        "def get_quest_data_fragment(previous_fragment, next_text_candidate):\n",
        "    return '\\n'.join(['BOF', previous_fragment, 'BUTTON', 'Далее', 'INPUT', 'Далее', 'BOF', next_text_candidate])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtiWg4rfAdWi"
      },
      "source": [
        "def calc_perplexity_based_score(text, fixed_part_perplexity, fixed_part_len):    \n",
        "    input_idx = tokenizer.encode(text, return_tensors='pt').cuda()\n",
        "    loss = gpt_model(input_idx, labels=input_idx)[0]\n",
        "    return (loss.exp()-fixed_part_perplexity)/(input_idx.shape[-1]-fixed_part_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_O0gv39GAdWi"
      },
      "source": [
        "human_written_fragments = ['Вы выходите на поляну и видите недостроенный стул из снега, возле которого лежит грустный плюшевый мишка. Хотите достроить?',\n",
        "  'Вы подошли к выходу из леса и еще можете успеть на последний автобус в город. Но вы так и не выяснили, что произошло с ребенком. Что будете делать?',\n",
        "  'Вы выходите к поляне, надеетесь, что идти по ней будет легче. Делаете шаг вперед и проваливаетесь по пояс. Развернетесь?',\n",
        " 'Вы слышите тот же детский голос снова. Но теперь ребенок не кричит, а репетирует «Я помню чудное мгновенье». Но почему он делает это в лесу?',\n",
        "  'Вы обнаруживаете следы на снегу, размер ноги определенно не как у ребенка. Посмотрите, куда они ведут.',\n",
        " 'Вы совсем забыли, откуда пришли. Может, найти дорогу назад важнее, чем понять, откуда доносились звуки?',\n",
        "  'Теперь голос доносится сверху, причем очень близко. Под вашими ногами валяется ботинок, ребенок сидит наверху и не хочет слезать в сугроб. Вы подаете ему обувь, он благодарит вас и говорит, что слезет, когда захочет.',\n",
        " 'Между деревьев вы обнаруживаете колонку, из которой доносится тот же детский крик. Вы выключаете ее, чтобы звуки больше никого не сбили с толку.',\n",
        "                          'Пора сразиться с чудовищем']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoo2rHLLAdWj"
      },
      "source": [
        "previous_fragments_to_score = [\n",
        "    'Вас все достало и вы ушли домой. Сколько можно находиться в этом лесу!',\n",
        "    'Вам очень интересно, откуда доносятся звуки. Вы тут, чтобы узнать это, и не хотите отвлекаться.',\n",
        "    'Вы уверены, что ничего страшного не произошло. Ребенок никуда не денется',\n",
        "    'Вы нашли труп',\n",
        "    'Лизу убьет научник',\n",
        "    'Лизу убьет руководитель практики',\n",
        "    'На вас напало пятнадцать единорогов',\n",
        "    'Кошки пушистые',\n",
        "    'Петя купил творог для сырников', \n",
        "    'Вы решили приступить к сражению'\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnrYX8MeAdWj"
      },
      "source": [
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AbDnt9TAdWj"
      },
      "source": [
        "scores = {}\n",
        "gpt_model.eval()\n",
        "with torch.no_grad():\n",
        "    for i, next_fragment in enumerate(human_written_fragments):\n",
        "        current_fragment_scores = []\n",
        "    \n",
        "        fixed_part = '\\n'.join(['BUTTON', 'Далее', 'INPUT', 'Далее', 'BOF', next_fragment])\n",
        "        fixed_part_loss, fixed_part_len = get_fixed_part_coefs(fixed_part)\n",
        "    \n",
        "        for previous_fragment in previous_fragments_to_score:\n",
        "            joined_fragment_to_score = get_quest_data_fragment(previous_fragment, next_fragment)\n",
        "            perplexity_based_score = calc_perplexity_based_score(joined_fragment_to_score, fixed_part_loss, fixed_part_len)\n",
        "            current_fragment_scores.append({'previous_fragment':previous_fragment, 'score':perplexity_based_score})\n",
        "        current_fragment_scores.sort(key=lambda x: x['score'])\n",
        "        scores[next_fragment] = current_fragment_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3mybJilAdWk",
        "outputId": "f12fab47-1260-4ef6-d9e6-d6113afa6e80"
      },
      "source": [
        "for next_fragment, next_fragment_scores in scores.items():\n",
        "    print(next_fragment)\n",
        "    for score_data in next_fragment_scores:\n",
        "        print(score_data['previous_fragment'], score_data['score'])\n",
        "    print('__________________________')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Вы выходите на поляну и видите недостроенный стул из снега, возле которого лежит грустный плюшевый мишка. Хотите достроить?\n",
            "Петя купил творог для сырников tensor(3.0162, device='cuda:0')\n",
            "Вы уверены, что ничего страшного не произошло. Ребенок никуда не денется tensor(3.0323, device='cuda:0')\n",
            "Вы решили приступить к сражению tensor(3.3744, device='cuda:0')\n",
            "Вы нашли труп tensor(5.7282, device='cuda:0')\n",
            "Кошки пушистые tensor(6.9726, device='cuda:0')\n",
            "Вам очень интересно, откуда доносятся звуки. Вы тут, чтобы узнать это, и не хотите отвлекаться. tensor(8.5286, device='cuda:0')\n",
            "На вас напало пятнадцать единорогов tensor(10.2027, device='cuda:0')\n",
            "Вас все достало и вы ушли домой. Сколько можно находиться в этом лесу! tensor(13.2297, device='cuda:0')\n",
            "Лизу убьет руководитель практики tensor(27.6494, device='cuda:0')\n",
            "Лизу убьет научник tensor(30.2868, device='cuda:0')\n",
            "__________________________\n",
            "Вы подошли к выходу из леса и еще можете успеть на последний автобус в город. Но вы так и не выяснили, что произошло с ребенком. Что будете делать?\n",
            "Вы решили приступить к сражению tensor(0.1937, device='cuda:0')\n",
            "Вы уверены, что ничего страшного не произошло. Ребенок никуда не денется tensor(0.2283, device='cuda:0')\n",
            "Кошки пушистые tensor(0.7777, device='cuda:0')\n",
            "Вы нашли труп tensor(1.2128, device='cuda:0')\n",
            "Петя купил творог для сырников tensor(2.7200, device='cuda:0')\n",
            "На вас напало пятнадцать единорогов tensor(7.3197, device='cuda:0')\n",
            "Вам очень интересно, откуда доносятся звуки. Вы тут, чтобы узнать это, и не хотите отвлекаться. tensor(7.8640, device='cuda:0')\n",
            "Вас все достало и вы ушли домой. Сколько можно находиться в этом лесу! tensor(7.9501, device='cuda:0')\n",
            "Лизу убьет руководитель практики tensor(12.0345, device='cuda:0')\n",
            "Лизу убьет научник tensor(26.4500, device='cuda:0')\n",
            "__________________________\n",
            "Вы выходите к поляне, надеетесь, что идти по ней будет легче. Делаете шаг вперед и проваливаетесь по пояс. Развернетесь?\n",
            "Кошки пушистые tensor(0.1959, device='cuda:0')\n",
            "Вы нашли труп tensor(0.7800, device='cuda:0')\n",
            "Петя купил творог для сырников tensor(2.5951, device='cuda:0')\n",
            "Вы уверены, что ничего страшного не произошло. Ребенок никуда не денется tensor(4.7617, device='cuda:0')\n",
            "Вы решили приступить к сражению tensor(5.7509, device='cuda:0')\n",
            "Вам очень интересно, откуда доносятся звуки. Вы тут, чтобы узнать это, и не хотите отвлекаться. tensor(6.4692, device='cuda:0')\n",
            "Лизу убьет научник tensor(7.8447, device='cuda:0')\n",
            "Вас все достало и вы ушли домой. Сколько можно находиться в этом лесу! tensor(8.0314, device='cuda:0')\n",
            "На вас напало пятнадцать единорогов tensor(8.6412, device='cuda:0')\n",
            "Лизу убьет руководитель практики tensor(10.2409, device='cuda:0')\n",
            "__________________________\n",
            "Вы слышите тот же детский голос снова. Но теперь ребенок не кричит, а репетирует «Я помню чудное мгновенье». Но почему он делает это в лесу?\n",
            "Кошки пушистые tensor(0.5891, device='cuda:0')\n",
            "Вы уверены, что ничего страшного не произошло. Ребенок никуда не денется tensor(2.7917, device='cuda:0')\n",
            "Петя купил творог для сырников tensor(2.9703, device='cuda:0')\n",
            "Вам очень интересно, откуда доносятся звуки. Вы тут, чтобы узнать это, и не хотите отвлекаться. tensor(3.2022, device='cuda:0')\n",
            "Вы нашли труп tensor(5.3175, device='cuda:0')\n",
            "Вас все достало и вы ушли домой. Сколько можно находиться в этом лесу! tensor(5.4332, device='cuda:0')\n",
            "Вы решили приступить к сражению tensor(6.6577, device='cuda:0')\n",
            "На вас напало пятнадцать единорогов tensor(7.8161, device='cuda:0')\n",
            "Лизу убьет руководитель практики tensor(15.2659, device='cuda:0')\n",
            "Лизу убьет научник tensor(20.8994, device='cuda:0')\n",
            "__________________________\n",
            "Вы обнаруживаете следы на снегу, размер ноги определенно не как у ребенка. Посмотрите, куда они ведут.\n",
            "Кошки пушистые tensor(2.8018, device='cuda:0')\n",
            "Вы уверены, что ничего страшного не произошло. Ребенок никуда не денется tensor(3.2145, device='cuda:0')\n",
            "Вы нашли труп tensor(3.2421, device='cuda:0')\n",
            "Петя купил творог для сырников tensor(4.0300, device='cuda:0')\n",
            "Вам очень интересно, откуда доносятся звуки. Вы тут, чтобы узнать это, и не хотите отвлекаться. tensor(6.3761, device='cuda:0')\n",
            "Вы решили приступить к сражению tensor(7.5166, device='cuda:0')\n",
            "На вас напало пятнадцать единорогов tensor(8.0035, device='cuda:0')\n",
            "Вас все достало и вы ушли домой. Сколько можно находиться в этом лесу! tensor(9.7841, device='cuda:0')\n",
            "Лизу убьет научник tensor(14.4461, device='cuda:0')\n",
            "Лизу убьет руководитель практики tensor(17.4960, device='cuda:0')\n",
            "__________________________\n",
            "Вы совсем забыли, откуда пришли. Может, найти дорогу назад важнее, чем понять, откуда доносились звуки?\n",
            "Кошки пушистые tensor(-0.8253, device='cuda:0')\n",
            "Вам очень интересно, откуда доносятся звуки. Вы тут, чтобы узнать это, и не хотите отвлекаться. tensor(2.1351, device='cuda:0')\n",
            "Вы нашли труп tensor(2.6722, device='cuda:0')\n",
            "Вы решили приступить к сражению tensor(3.0207, device='cuda:0')\n",
            "Петя купил творог для сырников tensor(4.5730, device='cuda:0')\n",
            "Вы уверены, что ничего страшного не произошло. Ребенок никуда не денется tensor(5.0882, device='cuda:0')\n",
            "На вас напало пятнадцать единорогов tensor(5.8388, device='cuda:0')\n",
            "Вас все достало и вы ушли домой. Сколько можно находиться в этом лесу! tensor(10.7833, device='cuda:0')\n",
            "Лизу убьет научник tensor(20.1574, device='cuda:0')\n",
            "Лизу убьет руководитель практики tensor(20.8927, device='cuda:0')\n",
            "__________________________\n",
            "Теперь голос доносится сверху, причем очень близко. Под вашими ногами валяется ботинок, ребенок сидит наверху и не хочет слезать в сугроб. Вы подаете ему обувь, он благодарит вас и говорит, что слезет, когда захочет.\n",
            "Кошки пушистые tensor(-4.4459, device='cuda:0')\n",
            "Вам очень интересно, откуда доносятся звуки. Вы тут, чтобы узнать это, и не хотите отвлекаться. tensor(0.0194, device='cuda:0')\n",
            "Вы уверены, что ничего страшного не произошло. Ребенок никуда не денется tensor(3.7593, device='cuda:0')\n",
            "Вы решили приступить к сражению tensor(5.6144, device='cuda:0')\n",
            "Вас все достало и вы ушли домой. Сколько можно находиться в этом лесу! tensor(16.7552, device='cuda:0')\n",
            "Вы нашли труп tensor(23.2396, device='cuda:0')\n",
            "Лизу убьет руководитель практики tensor(23.7801, device='cuda:0')\n",
            "На вас напало пятнадцать единорогов tensor(27.1151, device='cuda:0')\n",
            "Петя купил творог для сырников tensor(29.8166, device='cuda:0')\n",
            "Лизу убьет научник tensor(43.5201, device='cuda:0')\n",
            "__________________________\n",
            "Между деревьев вы обнаруживаете колонку, из которой доносится тот же детский крик. Вы выключаете ее, чтобы звуки больше никого не сбили с толку.\n",
            "Кошки пушистые tensor(-2.6484, device='cuda:0')\n",
            "Вы уверены, что ничего страшного не произошло. Ребенок никуда не денется tensor(1.6713, device='cuda:0')\n",
            "Вы нашли труп tensor(1.7521, device='cuda:0')\n",
            "Петя купил творог для сырников tensor(3.5048, device='cuda:0')\n",
            "Вас все достало и вы ушли домой. Сколько можно находиться в этом лесу! tensor(4.5951, device='cuda:0')\n",
            "Вам очень интересно, откуда доносятся звуки. Вы тут, чтобы узнать это, и не хотите отвлекаться. tensor(5.2489, device='cuda:0')\n",
            "На вас напало пятнадцать единорогов tensor(5.6778, device='cuda:0')\n",
            "Вы решили приступить к сражению tensor(7.2916, device='cuda:0')\n",
            "Лизу убьет руководитель практики tensor(14.6839, device='cuda:0')\n",
            "Лизу убьет научник tensor(25.5342, device='cuda:0')\n",
            "__________________________\n",
            "Пора сразиться с чудовищем\n",
            "Вы решили приступить к сражению tensor(0.8263, device='cuda:0')\n",
            "Кошки пушистые tensor(1.2558, device='cuda:0')\n",
            "Петя купил творог для сырников tensor(1.6365, device='cuda:0')\n",
            "Вы нашли труп tensor(1.7035, device='cuda:0')\n",
            "На вас напало пятнадцать единорогов tensor(1.7339, device='cuda:0')\n",
            "Вы уверены, что ничего страшного не произошло. Ребенок никуда не денется tensor(2.0316, device='cuda:0')\n",
            "Вас все достало и вы ушли домой. Сколько можно находиться в этом лесу! tensor(4.6771, device='cuda:0')\n",
            "Вам очень интересно, откуда доносятся звуки. Вы тут, чтобы узнать это, и не хотите отвлекаться. tensor(4.8199, device='cuda:0')\n",
            "Лизу убьет руководитель практики tensor(5.6593, device='cuda:0')\n",
            "Лизу убьет научник tensor(5.9913, device='cuda:0')\n",
            "__________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OiWeV19AdWk",
        "outputId": "cd2d1622-4e5d-49e2-c8a6-ba05cf467d22"
      },
      "source": [
        "i"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGwwtwTZAdWk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}